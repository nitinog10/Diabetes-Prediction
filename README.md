ğŸ©º Diabetes Prediction Model
Kaggle Playground Series â€“ Season 5, Episode 12 (S5E12)

This project builds a machine-learning classification model to predict the probability of diagnosed_diabetes using the Kaggle Playground Series â€“ S5E12 dataset.
The target leaderboard performance goal was an AUC-ROC â‰¥ 0.78940, with a full end-to-end pipeline including EDA, preprocessing, model selection, hyperparameter tuning, and submission generation.

ğŸ“ Dataset

The dataset originates from a synthetic deep learning model trained on the Diabetes Health Indicators Dataset. It includes:

Demographic variables

Lifestyle factors

Medical history

Clinical measurements

Target variable:
diagnosed_diabetes â€” a binary indicator (0/1) for diabetes diagnosis.

Files used:

train.csv

test.csv

sample_submission.csv

ğŸ”§ Methodology
1. Data Download & Setup

Initially attempted using Kaggle API, but encountered:

401 Client Error: Unauthorized

Invalid/missing kaggle.json

Competition rules not accepted

Solution: Manual upload of dataset files into Google Colab.

2. Exploratory Data Analysis (EDA)

Performed the following:

âœ” Basic Integrity Checks

Validated data types

Identified minimal missing values

âœ” Visualizations

Histograms (numerical features)

Count plots (categorical features)

Boxplots comparing numerical features & target

Count plots with hue = diagnosed_diabetes

Correlation heatmap

âœ” Key Findings

Strong associations with diabetes were found in:

age, bmi, waist_to_hip_ratio

systolic_bp, diastolic_bp

cholesterol_total, ldl_cholesterol, triglycerides

family_history_diabetes, hypertension_history, cardiovascular_history

Negative correlation:

hdl_cholesterol

Potential multicollinearity was also detected among numerical variables.

ğŸ§¹ Data Preprocessing
âœ” Missing Values

Rows with isolated missing entries (1 per column) were dropped in both train & test sets.

âœ” Type Conversion

Binary fields converted to:

Boolean â†’ Integer for modeling
(family_history_diabetes, hypertension_history, cardiovascular_history, diagnosed_diabetes)

âœ” Feature Engineering

Five new features were added:

BMI_Age_Interaction = bmi * age

WH_Ratio_Age_Interaction = waist_to_hip_ratio * age

BP_Interaction = systolic_bp * diastolic_bp

Cholesterol_Ratio = ldl_cholesterol / hdl_cholesterol
(Safe division handling zero/NaN)

History_Sum = sum of all family/medical history binary indicators

âœ” Scaling & Encoding

Using ColumnTransformer:

StandardScaler â†’ numerical variables

OneHotEncoder â†’ categorical variables

id column removed before transformation

ğŸ¤– Model Training & Selection
Baseline Model

Logistic Regression

Accuracy: 0.6623

AUC-ROC: 0.6904

Advanced Models Tested
Model	Accuracy	AUC-ROC
RandomForestClassifier	0.6562	0.6829
XGBClassifier	0.6722	0.7053

XGBoost performed best, becoming the primary candidate for optimization.

âš™ï¸ Hyperparameter Tuning

Approach: GridSearchCV (3-fold cross-validation)
Parameters tuned:

n_estimators

max_depth

learning_rate

subsample

colsample_bytree

Best parameters identified:

{
    'colsample_bytree': 0.7,
    'learning_rate': 0.05,
    'max_depth': 5,
    'n_estimators': 300,
    'subsample': 0.9
}

ğŸ“ˆ Optimized Performance

Cross-validated AUC-ROC: 0.7164

ğŸ“¤ Prediction & Submission
âœ” Final Model

Retrained optimized XGBoost on all processed training data.

âœ” Predictions

Generated prediction probabilities for all test rows.

âœ” Submission File (submission2.csv)

Contains 300,000 rows as required

Rows missing from processed test set filled with default probability 0.5

Columns:

id

diagnosed_diabetes (probability)

âš  Kaggle Public Score

0.57840 â€” significantly lower than local validation results.
Likely causes:

Validationâ€“test distribution mismatch

Submission misalignment

Differences in feature preprocessing

Issues with missing-row probability padding

ğŸš§ Next Steps / Future Improvements
âœ” Kaggle Submission Fixes

Resolve 401 authorization errors

Ensure:

API credentials correctly configured

Competition rules accepted

Proper dataset file structure

âœ” Modeling Improvements

Try LightGBM, CatBoost, or small neural nets

More advanced feature engineering:

Polynomial features

Clinical domain-based ratios & interactions

Apply robust cross-validation:

Stratified K-Fold (recommended)

Ensemble & stacking approaches

Perform post-hoc error analysis to find major failure patterns

ğŸ“¦ Repository Structure
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
â”œâ”€â”€ sample_submission.csv
â”œâ”€â”€ diabetes_prediction.ipynb
â”œâ”€â”€ submission2.csv
â””â”€â”€ README.md

ğŸ Conclusion

This project implements a complete Kaggle workflowâ€”from EDA through modeling and submission. While local performance exceeded baseline expectations, public leaderboard results revealed opportunities for improved validation and preprocessing consistency.
